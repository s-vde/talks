
---
<div style="width: 55%; float: left;">
</div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler1.png' height="400"/>
</div>

???
The Scheduler object maintains a ThreadPool which at any point during the execution of the program
contains an entry for every active program thread.
This entry contains the next instruction of the corresponding thread, and is initially empty.
It also contains a semaphore, which allows the scheduler to control the thread.

---
count: false
<div style="width: 55%; float: left;">
<pre><code class="language-cpp">
scheduler::post_instruction(lock, mut.addr, debug_info);
mut.lock();
</code></pre>
</div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler1.png' height="400"/>
</div>

???
Every memory instruction, lock or unlock instruction, thread creation abd joining instruction
in the original source code is instrumented. That is, before each such instruction, the 
instrumentation pass has inserted a call to scheduler's member the function 
post_instruction().

Inside the post_instruction function, the calling thread sets the instruction field in its 
associated entry in the thread pool.

---
count: false
<div style="width: 55%; float: left;">
<pre><code class="language-cpp">
scheduler::post_instruction(lock, mut.addr, debug_info);
mut.lock();
</code></pre>
</div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler2.png' height="400"/>
</div>

???
Then it waits on its semaphore.

---
count: false
<div style="width: 55%; float: left;">
<pre><code class="language-cpp">
scheduler::post_instruction(lock, mut.addr, debug_info);
mut.lock();
</code></pre>
</div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler3.png' height="400"/>
</div>

---
count: false
<div style="width: 55%; float: left;"><pre><code class="language-cpp">
scheduler::scheduler_thread(schedule)
{
   trace_t trace;
   unsigned int round = 0;
   
   while (!done)
   {
      // wait until all active threads posted an instruction
      
      int next_id = schedule[round];
      
      // record the thread pool and the next instruction
      trace.push_back(thread_pool.instructions(), 
                      thread_pool[next_tid].instruction);
      
      // allow the next thread to progress until its next 
      // post_instruction call
      thread_pool.semaphores()[next_tid].post();
      
      ++round;
   }
}
</code></pre></div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler4.png' height="400"/>
</div>

???
The scheduler thread gets as input a schedule, which is a sequence of thread id's.
At every scheduling round, the scheduler thread first waits until all the threads that are 
registered in the thread pool have an instruction posted.
Then it looks up in the schedule which thread it should schedule in the current round.
It adds the instruction posted by that thread to the execution trace, together with a snapshot 
of the current thread pool.

---
count: false
<div style="width: 55%; float: left;"><pre><code class="language-cpp">
scheduler::scheduler_thread(schedule)
{
   trace_t trace;
   unsigned int round = 0;
   
   while (!done)
   {
      // wait until all active threads posted an instruction
      
      int next_id = schedule[round];
      
      // record the thread pool and the next instruction
      trace.push_back(thread_pool.instructions(), 
                      thread_pool[next_tid].instruction);
      
      // allow the next thread to progress until its next 
      // post_instruction call
      thread_pool.semaphores()[next_tid].post();
      
      ++round;
   }
}
</code></pre></div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler5.png' height="400"/>
</div>

???
For the selected thread, it sets the associated semaphore to true,
notifies the thread that it may continue executing, and increases the round.

---
count: false
<div style="width: 55%; float: left;">
<pre><code class="language-cpp">
scheduler::post_instruction(lock, mut.addr, debug_info);
mut.lock();

.
. // other instructions
.

scheduler::post_instruction(spawn, thr.id, debug_info);
std::thread thr(start_routine);
</code></pre>
</div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler5.png' height="400"/>
</div>

???
The respective thread is no longer blocked on its semaphore, and can execute its original 
instruction, in this case locking a mutex.
It keeps executing until the next call to scheduler::post_instruction.

---
count: false
<div style="width: 55%; float: left;">
<pre><code class="language-cpp">
scheduler::post_instruction(lock, mut.addr, debug_info);
mut.lock();

.
. // other instructions
.

scheduler::post_instruction(spawn, thr.id, debug_info);
std::thread thr(start_routine);
</code></pre>
</div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler6.png' height="400"/>
</div>

???
It then again sets its instruction field in the thread pool and blocks on its semaphore.

---
count: false
<div style="width: 55%; float: left;">
</div>
<div style="width: 40%; float: right;">
   <img src='./images/scheduler7.png' height="400"/>
</div>

???
At each point in time, there is at most one thread that is not blocked on its semaphore.
This forces the underlying operating system's scheduler to schedule exactly that thread.




<br/>
<!-- TODO: refine -->
In audio development, concurrency is a big topic, as at the core, there is the audio processing, 
that has to run in real-time.
This audio processing runs in a dedicated real-time thread.
At the same time, it has to synchronize with user input through for example the GUI or the hardware.
This synchronization has to happen smoothly so that the audio processing is never waiting too long 
to deliver the next buffer in time.
My interest is mainly in assuring the correctness of this synchronization.


---
count: false
<div class="animation_bs" style="margin-right: 1em;">
   .right[<img src='./generated_trees/background_thread.cpp/bounded_search/1/trees/full_schedules.png' height="560"/>]
</div>


---
layout: true
#### Systematic Exploration - Exploration Algorithms
# Bounded Exploration
<span class="h_example">background_thread.cpp, preemptions=2</span>
---
---
count: false
<div class="animation_bs" style="margin-right: 1em; margin-top: 5em;">
   .right[<img src='./generated_trees/background_thread.cpp/bounded_search/2/trees/full_schedules.png' width="1100"/>]
</div>

<!-- Coverage Guarantees -->

--
count: false
- Complete coverage: all concurrency bugs in the program are found
--
count: false
- Partial coverage: all concurrency bugs with a certain property are found
   e.g.: 
--
count: false
   - all bugs reachable by a schedule of length 10
--
count: false
   - all bugs reachable by a schedule with at most 2 context-switches

<!--
}
end_section:section:Introduction -->

<!-- example:
            {
-->
---
```cpp
int x, y, z = 0;

int main()
{
   thread t1([]{
      if (x == 1)
         y = 1;
   });
   
   thread t2([]{
      x = 1;
      z = x + y;
   });
}                                   
```

---
```cpp
t1                   t2             x,    y,    z

x == 1?                             0,    0,    0
                     x = 1          1,    0,    0
                     read y         1,    0,    0 
                     z = x + y      1,    0,    1
```

--
count: false
```cpp
t1                   t2             x,    y,    z

                     x = 1          1,    0,    0
x == 1?                             1,    0,    0
y = 1                               1,    1,    0
                     read y         1,    1,    0 
                     z = x + y      1,    1,    2                                   
```

<!--
            }
end_example: -->

---
# TODO Content
- Comparison with CHESS, Maple 
   * Maple: based on PIN binary instrumentation tool (unmodified x86 binaries)
      * Framework for building dynamic analysis tools
      * AFAIK doens't have the exploration algorithms incorporated
   * CHESS:
- Comparison Static Analysis
- Benchmarking
- Depth-First Search animation
- How do the libs work
- Explain POR
- Example of correct program
- Combination Bounded Search and POR

---
# TODO Examples
- dining_philosophers instead of background_thread because it requires bounded search with 
  at least one preemption
- work_stealing_queue
- bank_accoutn with deposit/withdraw

---
# TODO Pictures
- Move Status to center of branch leaf
- Figure out the right nodesep
- Rename variables + get rid of the addresses to make nodesep lower possible


<!-- =============================================================================================================== -->
<!-- notes:
* Many tools available for testing / verifying sequential code (that is hard enough already!);
* Tool still in progress: not full support of C++11 memory model (e.g. visible sequences of side effects, atomics).

* Even though we see a tendency towards more and more high-level concurrency constructs (e.g. futures, coroutines) and 
programmers are more and more discouraged to use std::thread, and std::mutex, which become implementation details, there 
are domains where exactly these implementation details still matter (e.g. realtime systems, cyberphysical systems).
* Other examples such as CppMem (http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem/).
* Runtime nature of the tool, but can still prove completeness of the exploration tree (e.q. using Coq).
* Something about the implementation details, i.e. vector clocks?


* Difference between software testing and software verification;
* General limitations of software verification and dynamic verification, e.g. non-halting programs excluded;
* Verification w.r.t. a *class* of bugs/errors, a specification (e.g. Datarace free);
* Difference between static analysis and dynamic analysis (e.g. examples from Flanagan/Godefroid).

section:Concurrency and Concurrency Errors 
- Test input is a program and a schedule, observation is execution/trace and execution result
- Difficult to reason about the interaction of threads

* Think about examples:
    - background_thread
    - workstealing_queue
    - double_instance
    - Depth-bounding examples from the paper, showing that empirically, many bugs have small depth
    - Example with large depth
    - Example where POR and optimal POR differ a lot
-->

---
exclude: true
# Concurrency Error Detectors
### ThreadSanitzer
#### Runtime library
The `__tsan_` functions are callbacks to a Runtime Library (part of clang-rt)

Maintains a state maschine using shadow state for analysis

---
exclude: true
Helgrind
- Program is run on synthetic CPU provided by Valgrind Core 
- Threads are fully serialzed (only single CPU used)

---
exclude: true
# ThreadSanitizer & Helgrind: Data Races
Limited information in *single* execution:
<br/><br/><br/>
.center[<img src='./images/jpg/tsan_data-race-branch-hb.jpg' height="375"/>]

<!--- section:SYSTEMATIC_EXPLORATION -->

---
# Taking Control Over the Thread Interleavings
#### LLVM IR Instumentation Pass

Replace 
```cpp
pthread_create(pid, attr, start_routine, args)
pthread_join(pid)
``` 
by 
```cpp 
wrapper_spawn_thread(pid, attr, start_routine, args)
wrapper_pthread_join()
```

#### Scheduler
```cpp
void wrapper_spawn_thread(pid, attr, start_routine, args)
{
   semaphores.insert({ pid, semaphore() })
   pthread_create(pid, attr, start_routine, args)
}
```

---
count: false
# Taking Control Over the Thread Interleavings
#### LLVM IR Instumentation Pass

Insert call to potentially *visible* instructions
```
wrap_post_task(instruction(store, %2, is_atomic))
store i32 %0, i32* %2
```

#### Scheduler
```cpp
void wrapper_post_task(instruction)
{
   task_pool.insert({ this_thread::id(), instruction });
   semaphores[this_thread::id()].wait();
   // wait for turn
   
   task_pool.remove(this_thread::id());
   // perform instructions
}
```

---
count: false
# Taking Control Over the Thread Interleavings
#### Scheduler

```cpp
void scheduler_thread(schedule)
{
   for (thread_id : schedule)
   {
      wait_until(task_pool.contains_key(thread_id));
      current_thread_id = thread_id;
      semaphore[thread_id].post();
      // notify the waiting thread
   }
}
```

---
# Bounded Search

### Advantages:
- Very fast for low bounds
- Quantifiable coverage
- Incremental

### Disadvantages:
- Incomplete
- For high bounds not better than depth first search

---
# Partial Order Reduction

Different interleavings may yield *equivalent* executions:
Ideally explore only a single one of those

--
count: false
#### Dependence Relation

```cpp
bool dependent(memory_instr1, memory_instr2)
{
   return same_thread(memory_instr1, memory_instr2) || 
          ( same_operand(memory_instr1, memory_instr2) &&
            memory_instr1.is_write() || memory_inst2.is_write() );
}
```
```cpp
bool dependent(lock_instr1, lock_instr2)
{
   return same_thread(lock_instr1, lock_instr2) || 
          ( same_operand(lock_instr1, lock_instr2) &&
            lock_instr1.is_lock() && lock_inst2.is_lock() );
}
```

---
# Partial Order Reduction 

<br/>
<tr>
    <td><img src='./images/jpg/happens_before_equivalence_class_1.jpg' width="350"/></td>
    <td><img src="./images/jpg/happens_before_equivalence_class_2.jpg" width="350"/></td>
</tr>

---
# Partial Order Reduction

### Advantages:
- Complete coverage

### Disadvantages:
- Still infeasible for large state-spaces with many dependencies
- Not incremental


---
```

thread->has_posted()
   m_status == POSTED

thread->post(task)
    m_is_enabled = Objects[task.op]->post(task)
    m_status = POSTED
    // ... wait for turn ...
    m_control_handle->wait()
    // ... perform task ...
    
thread->grant_execution_right()
   m_status == CONTROL
   m_control_handle.post()
   
    
    
    
scheduler::schedule_thread(tid)
   m_pool.set_current(tid)
      m_tasks.erase(tid)                              !!!

      
    

TaskPool -> datarace detection
TaskPool -> enabledness analysis
```

--
count: false
<div style="vertical-align: top; float: right; width: 45%;"><pre><code class="language-cpp">
// same operand and one write
dependent(  1 Load x,      2 Store x   );

// same operand, but no write
!dependent( 1 Load x,      2 Load x    );


// coenabled, and disable each other
dependent(   1 Lock m,     2 Lock m    );

// coenabled, and enable/disable each other       
dependent(   1 Trylock m,  2 Unlock m  );

// not coenabled
!dependent(  1 Lock m,     2 Unlock m  );
</code></pre></div>
